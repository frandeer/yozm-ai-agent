from typing import Dict, Any, Literal
from langgraph.graph import StateGraph, START, END
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import json


# â‘  ê²Œì„ ìƒíƒœ ì •ì˜
class StoryGameState(BaseModel):
    story_context: str = Field(default="", description="í˜„ì¬ê¹Œì§€ì˜ ìŠ¤í† ë¦¬ ë§¥ë½")
    current_scene: str = Field(default="", description="í˜„ì¬ ì¥ë©´ ì„¤ëª…")
    choices: list[str] = Field(default_factory=list, description="ì‚¬ìš©ì ì„ íƒì§€")
    user_choice: str = Field(default="", description="ì‚¬ìš©ìê°€ ì„ íƒí•œ ë‚´ìš©")
    turn_count: int = Field(default=0, description="ì§„í–‰ëœ í„´ ìˆ˜")
    max_turns: int = Field(default=5, description="ìµœëŒ€ í„´ ìˆ˜")
    game_status: str = Field(default="playing", description="ê²Œì„ ìƒíƒœ: playing, ended")


# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.8)


# â‘¡ ìŠ¤í† ë¦¬ ì‹œì‘ ë…¸ë“œ
def start_story(state: StoryGameState) -> Dict[str, Any]:
    """ê²Œì„ì„ ì‹œì‘í•˜ê³  ì²« ë²ˆì§¸ ì¥ë©´ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("\n=== ğŸ® AI ìŠ¤í† ë¦¬ ì–´ë“œë²¤ì²˜ ê²Œì„ ì‹œì‘! ===\n")
    
    system_prompt = """ë‹¹ì‹ ì€ ì°½ì˜ì ì¸ ì¸í„°ë™í‹°ë¸Œ ìŠ¤í† ë¦¬ ì‘ê°€ì…ë‹ˆë‹¤.
íŒíƒ€ì§€ ì–´ë“œë²¤ì²˜ ìŠ¤í† ë¦¬ì˜ ì‹œì‘ ì¥ë©´ì„ ìƒì„±í•˜ì„¸ìš”.

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "scene": "ì¥ë©´ ì„¤ëª… (3-4ë¬¸ì¥, ìƒìƒí•˜ê³  í¥ë¯¸ì§„ì§„í•˜ê²Œ)",
  "choices": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3"]
}

ìŠ¤í† ë¦¬ëŠ” í¥ë¯¸ë¡­ê³  ëª°ì…ê° ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”."""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content="ëª¨í—˜ì´ ì‹œì‘ë˜ëŠ” ì²« ì¥ë©´ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")
    ]
    
    response = llm.invoke(messages)
    result = json.loads(response.content)
    
    scene = result["scene"]
    choices = result["choices"]
    
    print(f"ğŸ“– {scene}\n")
    print("ğŸ¯ ì„ íƒì§€:")
    for i, choice in enumerate(choices, 1):
        print(f"  {i}. {choice}")
    
    return {
        "story_context": scene,
        "current_scene": scene,
        "choices": choices,
        "turn_count": 1,
        "game_status": "playing"
    }


# â‘¢ ì‚¬ìš©ì ì„ íƒ ì…ë ¥ ë…¸ë“œ
def get_user_choice(state: StoryGameState) -> Dict[str, Any]:
    """ì‚¬ìš©ìë¡œë¶€í„° ì„ íƒì„ ì…ë ¥ë°›ìŠµë‹ˆë‹¤."""
    print(f"\n--- í„´ {state.turn_count} ---")
    
    while True:
        try:
            choice_num = int(input("ì„ íƒí•˜ì„¸ìš” (ë²ˆí˜¸ ì…ë ¥): "))
            if 1 <= choice_num <= len(state.choices):
                user_choice = state.choices[choice_num - 1]
                print(f"âœ… ì„ íƒ: {user_choice}")
                return {"user_choice": user_choice}
            else:
                print(f"1-{len(state.choices)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        except ValueError:
            print("ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


# â‘£ ë‹¤ìŒ ì¥ë©´ ìƒì„± ë…¸ë“œ (AIê°€ ìŠ¤í† ë¦¬ ì§„í–‰)
def generate_next_scene(state: StoryGameState) -> Dict[str, Any]:
    """ì‚¬ìš©ì ì„ íƒì— ë”°ë¼ ë‹¤ìŒ ì¥ë©´ì„ AIê°€ ìƒì„±í•©ë‹ˆë‹¤."""
    print("\nğŸ¤” AIê°€ ë‹¤ìŒ ì´ì•¼ê¸°ë¥¼ ìƒì„± ì¤‘...\n")
    
    system_prompt = f"""ë‹¹ì‹ ì€ ì¸í„°ë™í‹°ë¸Œ ìŠ¤í† ë¦¬ ì‘ê°€ì…ë‹ˆë‹¤.
ì´ì „ ìŠ¤í† ë¦¬ì™€ ì‚¬ìš©ìì˜ ì„ íƒì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì¥ë©´ì„ ìƒì„±í•˜ì„¸ìš”.

ì´ì „ ë§¥ë½: {state.story_context}
ì‚¬ìš©ì ì„ íƒ: {state.user_choice}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "scene": "ë‹¤ìŒ ì¥ë©´ ì„¤ëª… (3-4ë¬¸ì¥, ì‚¬ìš©ì ì„ íƒì˜ ê²°ê³¼ë¥¼ ë°˜ì˜)",
  "choices": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3"]
}}

ìŠ¤í† ë¦¬ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ê³  í¥ë¯¸ì§„ì§„í•´ì•¼ í•©ë‹ˆë‹¤."""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content="ë‹¤ìŒ ì¥ë©´ì„ ìƒì„±í•´ì£¼ì„¸ìš”.")
    ]
    
    response = llm.invoke(messages)
    result = json.loads(response.content)
    
    scene = result["scene"]
    choices = result["choices"]
    
    # ë§¥ë½ ì—…ë°ì´íŠ¸
    new_context = f"{state.story_context}\n\n[ì„ íƒ: {state.user_choice}]\n{scene}"
    
    print(f"ğŸ“– {scene}\n")
    print("ğŸ¯ ì„ íƒì§€:")
    for i, choice in enumerate(choices, 1):
        print(f"  {i}. {choice}")
    
    return {
        "story_context": new_context,
        "current_scene": scene,
        "choices": choices,
        "turn_count": state.turn_count + 1
    }


# â‘¤ ìŠ¤í† ë¦¬ ì¢…ë£Œ ë…¸ë“œ
def end_story(state: StoryGameState) -> Dict[str, Any]:
    """ìŠ¤í† ë¦¬ë¥¼ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤."""
    print("\nğŸ¬ AIê°€ ìŠ¤í† ë¦¬ ê²°ë§ì„ ìƒì„± ì¤‘...\n")
    
    system_prompt = f"""ë‹¹ì‹ ì€ ìŠ¤í† ë¦¬ ì‘ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ìŠ¤í† ë¦¬ë¥¼ ê°ë™ì ì´ê³  ë§Œì¡±ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.

ìŠ¤í† ë¦¬ ë§¥ë½:
{state.story_context}

ë§ˆì§€ë§‰ ì„ íƒ: {state.user_choice}

2-3ë¬¸ì¥ìœ¼ë¡œ ë©‹ì§„ ê²°ë§ì„ ì‘ì„±í•˜ì„¸ìš”."""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content="ìŠ¤í† ë¦¬ë¥¼ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.")
    ]
    
    response = llm.invoke(messages)
    ending = response.content
    
    print(f"ğŸ“– {ending}\n")
    print("ğŸ‰ === ê²Œì„ ì¢…ë£Œ === ğŸ‰")
    
    return {
        "current_scene": ending,
        "game_status": "ended"
    }


# â‘¥ ë¼ìš°íŒ… í•¨ìˆ˜
def route_game(state: StoryGameState) -> Literal["continue", "end"]:
    """ê²Œì„ ì§„í–‰ ìƒíƒœì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    if state.turn_count >= state.max_turns:
        return "end"
    return "continue"


# â‘¦ ê·¸ë˜í”„ ìƒì„±
def create_story_game_graph():
    """AI ìŠ¤í† ë¦¬ ì–´ë“œë²¤ì²˜ ê²Œì„ ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    workflow = StateGraph(StoryGameState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("start", start_story)
    workflow.add_node("get_choice", get_user_choice)
    workflow.add_node("generate", generate_next_scene)
    workflow.add_node("ending", end_story)
    
    # ì—£ì§€ ì—°ê²°
    workflow.add_edge(START, "start")
    workflow.add_edge("start", "get_choice")
    
    # ì¡°ê±´ë¶€ ì—£ì§€ - ê²Œì„ ê³„ì† ë˜ëŠ” ì¢…ë£Œ
    workflow.add_conditional_edges(
        "get_choice",
        route_game,
        {
            "continue": "generate",
            "end": "ending"
        }
    )
    
    # ë‹¤ìŒ ì¥ë©´ ìƒì„± í›„ ë‹¤ì‹œ ì„ íƒìœ¼ë¡œ (ë£¨í”„!)
    workflow.add_edge("generate", "get_choice")
    workflow.add_edge("ending", END)
    
    return workflow.compile()


def main():
    print("=== AI ìŠ¤í† ë¦¬ ì–´ë“œë²¤ì²˜ ê²Œì„ (LangGraph + LLM) ===")
    print("AIê°€ ìƒì„±í•˜ëŠ” ìŠ¤í† ë¦¬ë¥¼ ë”°ë¼ ëª¨í—˜ì„ ë– ë‚˜ë³´ì„¸ìš”!\n")
    
    app = create_story_game_graph()
    
    # ê²Œì„ ì‹¤í–‰
    initial_state = StoryGameState(max_turns=4)  # 4í„´ ì§„í–‰
    result = app.invoke(initial_state)
    
    print(f"\nì´ {result['turn_count']}í„´ ì§„í–‰ë¨")
    
    # ê·¸ë˜í”„ ì‹œê°í™”
    try:
        mermaid_png = app.get_graph().draw_mermaid_png()
        with open("./04_ai_story_adventure.png", "wb") as f:
            f.write(mermaid_png)
        print("ê·¸ë˜í”„ê°€ 04_ai_story_adventure.pngë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ê·¸ë˜í”„ ì¶œë ¥ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()

