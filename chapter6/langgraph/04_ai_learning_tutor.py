from typing import Dict, Any, Literal
from langgraph.graph import StateGraph, START, END
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import json


# â‘  í•™ìŠµ ìƒíƒœ ì •ì˜
class TutorState(BaseModel):
    topic: str = Field(default="", description="í•™ìŠµ ì£¼ì œ")
    explanation: str = Field(default="", description="AIì˜ ì„¤ëª…")
    quiz_question: str = Field(default="", description="í€´ì¦ˆ ë¬¸ì œ")
    quiz_answer: str = Field(default="", description="ì •ë‹µ")
    quiz_choices: list[str] = Field(default_factory=list, description="ì„ íƒì§€")
    user_answer: str = Field(default="", description="ì‚¬ìš©ì ë‹µë³€")
    feedback: str = Field(default="", description="í”¼ë“œë°±")
    score: int = Field(default=0, description="ì ìˆ˜")
    quiz_count: int = Field(default=0, description="í‘¼ í€´ì¦ˆ ìˆ˜")
    max_quizzes: int = Field(default=3, description="ìµœëŒ€ í€´ì¦ˆ ìˆ˜")
    status: str = Field(default="explaining", description="ìƒíƒœ: explaining, quizzing, reviewing, done")
    previous_questions: list[str] = Field(default_factory=list, description="ì´ì „ì— ë‚¸ ë¬¸ì œë“¤")


# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)


# â‘¡ ì£¼ì œ ì„¤ëª… ë…¸ë“œ
def explain_topic(state: TutorState) -> Dict[str, Any]:
    """AIê°€ ì£¼ì œë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤."""
    topic = state.topic
    
    if state.quiz_count == 0:
        print(f"\n=== ğŸ“š AI í•™ìŠµ íŠœí„° ì‹œì‘! ===")
        print(f"ì£¼ì œ: {topic}\n")
    
    system_prompt = f"""ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
'{topic}' ì£¼ì œë¥¼ ì‰½ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.

3-4ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ê°œë…ì„ ì„¤ëª…í•˜ë˜, ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”."""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"{topic}ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
    ]
    
    response = llm.invoke(messages)
    explanation = response.content
    
    print(f"ğŸ“– ì„¤ëª…:\n{explanation}\n")
    
    return {
        "explanation": explanation,
        "status": "quizzing"
    }


# â‘¢ í€´ì¦ˆ ìƒì„± ë…¸ë“œ
def generate_quiz(state: TutorState) -> Dict[str, Any]:
    """í•™ìŠµ ë‚´ìš©ì— ëŒ€í•œ í€´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    print("ğŸ§  í€´ì¦ˆë¥¼ ìƒì„± ì¤‘...\n")
    
    # ì´ì „ ë¬¸ì œë“¤ì´ ìˆìœ¼ë©´ í‘œì‹œ
    previous_questions_text = ""
    if state.previous_questions:
        previous_questions_text = "\n\nì´ë¯¸ ë‚¸ ë¬¸ì œë“¤ (ì¤‘ë³µ ê¸ˆì§€):\n" + "\n".join(
            f"- {q}" for q in state.previous_questions
        )
    
    system_prompt = f"""ë‹¹ì‹ ì€ í€´ì¦ˆ ì¶œì œìì…ë‹ˆë‹¤.
ë‹¤ìŒ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ 4ì§€ì„ ë‹¤ í€´ì¦ˆë¥¼ ë§Œë“œì„¸ìš”:

{state.explanation}
{previous_questions_text}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "question": "ì§ˆë¬¸ (ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ)",
  "choices": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3", "ì„ íƒì§€4"],
  "answer": "ì •ë‹µ ì„ íƒì§€ì˜ ì •í™•í•œ í…ìŠ¤íŠ¸"
}}

ì¤‘ìš”: 
- ì´ì „ì— ë‚¸ ë¬¸ì œì™€ ì™„ì „íˆ ë‹¤ë¥¸ ê°ë„ì˜ ë¬¸ì œë¥¼ ë§Œë“œì„¸ìš”
- ê°™ì€ ê°œë…ì˜ ë‹¤ë¥¸ ì¸¡ë©´ì„ ë‹¤ë£¨ì„¸ìš”
- ë‚œì´ë„ëŠ” ì¤‘ê°„ ì •ë„ë¡œ, ì´í•´ë„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë¬¸ì œë¥¼ ë§Œë“œì„¸ìš”"""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content="í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")
    ]
    
    response = llm.invoke(messages)
    result = json.loads(response.content)
    
    question = result["question"]
    choices = result["choices"]
    answer = result["answer"]
    
    print(f"â“ í€´ì¦ˆ #{state.quiz_count + 1}")
    print(f"{question}\n")
    for i, choice in enumerate(choices, 1):
        print(f"  {i}. {choice}")
    
    # ì´ì „ ë¬¸ì œ ëª©ë¡ì— ì¶”ê°€
    updated_previous = state.previous_questions.copy()
    updated_previous.append(question)
    
    return {
        "quiz_question": question,
        "quiz_choices": choices,
        "quiz_answer": answer,
        "previous_questions": updated_previous,
        "status": "reviewing"
    }


# â‘£ ë‹µë³€ ì…ë ¥ ë° í‰ê°€ ë…¸ë“œ
def review_answer(state: TutorState) -> Dict[str, Any]:
    """ì‚¬ìš©ì ë‹µë³€ì„ ë°›ê³  AIê°€ í‰ê°€í•©ë‹ˆë‹¤."""
    print()
    
    # ì‚¬ìš©ì ë‹µë³€ ì…ë ¥
    while True:
        try:
            choice_num = int(input("ë‹µì„ ì„ íƒí•˜ì„¸ìš” (ë²ˆí˜¸ ì…ë ¥): "))
            if 1 <= choice_num <= len(state.quiz_choices):
                user_answer = state.quiz_choices[choice_num - 1]
                break
            else:
                print(f"1-{len(state.quiz_choices)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        except ValueError:
            print("ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    # ì •ë‹µ í™•ì¸
    is_correct = user_answer == state.quiz_answer
    
    if is_correct:
        print("âœ… ì •ë‹µì…ë‹ˆë‹¤!")
        new_score = state.score + 1
    else:
        print(f"âŒ í‹€ë ¸ìŠµë‹ˆë‹¤. ì •ë‹µì€: {state.quiz_answer}")
        new_score = state.score
    
    # AI í”¼ë“œë°± ìƒì„±
    print("ğŸ’¬ AI í”¼ë“œë°± ìƒì„± ì¤‘...\n")
    
    system_prompt = f"""ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
í•™ìƒì˜ ë‹µë³€ì— ëŒ€í•´ í”¼ë“œë°±ì„ ì£¼ì„¸ìš”.

ì§ˆë¬¸: {state.quiz_question}
ì •ë‹µ: {state.quiz_answer}
í•™ìƒ ë‹µë³€: {user_answer}
ê²°ê³¼: {'ì •ë‹µ' if is_correct else 'ì˜¤ë‹µ'}

{'ì¹­ì°¬í•˜ë©°' if is_correct else 'ê²©ë ¤í•˜ë©°'} 2-3ë¬¸ì¥ìœ¼ë¡œ í”¼ë“œë°±ì„ ì‘ì„±í•˜ì„¸ìš”.
{'ì¶”ê°€ë¡œ ê´€ë ¨ ì§€ì‹ì„ ì•Œë ¤ì£¼ì„¸ìš”.' if is_correct else 'ì™œ í‹€ë ¸ëŠ”ì§€, ì˜¬ë°”ë¥¸ ê°œë…ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.'}"""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content="í”¼ë“œë°±ì„ ì£¼ì„¸ìš”.")
    ]
    
    response = llm.invoke(messages)
    feedback = response.content
    
    print(f"ğŸ“ {feedback}\n")
    
    return {
        "user_answer": user_answer,
        "feedback": feedback,
        "score": new_score,
        "quiz_count": state.quiz_count + 1,
        "status": "quizzing"
    }


# â‘¤ í•™ìŠµ ì™„ë£Œ ë…¸ë“œ
def finish_learning(state: TutorState) -> Dict[str, Any]:
    """í•™ìŠµì„ ë§ˆë¬´ë¦¬í•˜ê³  ìµœì¢… í‰ê°€ë¥¼ ì œê³µí•©ë‹ˆë‹¤."""
    print("\n=== ğŸ“ í•™ìŠµ ì™„ë£Œ! ===\n")
    
    score = state.score
    total = state.quiz_count
    percentage = (score / total * 100) if total > 0 else 0
    
    print(f"ìµœì¢… ì ìˆ˜: {score}/{total} ({percentage:.0f}%)")
    
    # AI ì´í‰ ìƒì„±
    system_prompt = f"""ë‹¹ì‹ ì€ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
í•™ìƒì˜ í•™ìŠµ ê²°ê³¼ì— ëŒ€í•œ ì´í‰ì„ ì‘ì„±í•˜ì„¸ìš”.

ì£¼ì œ: {state.topic}
ì ìˆ˜: {score}/{total}

ê²©ë ¤ì™€ í•¨ê»˜ 2-3ë¬¸ì¥ìœ¼ë¡œ ì´í‰ì„ ì‘ì„±í•˜ì„¸ìš”."""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content="ì´í‰ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")
    ]
    
    response = llm.invoke(messages)
    summary = response.content
    
    print(f"ğŸ“¢ ì„ ìƒë‹˜ ì´í‰:\n{summary}\n")
    
    return {"status": "done"}


# â‘¥ ë¼ìš°íŒ… í•¨ìˆ˜
def route_learning(state: TutorState) -> Literal["continue", "finish"]:
    """í•™ìŠµ ì§„í–‰ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    if state.quiz_count >= state.max_quizzes:
        return "finish"
    return "continue"


# â‘¦ ê·¸ë˜í”„ ìƒì„±
def create_tutor_graph():
    """AI í•™ìŠµ íŠœí„° ê·¸ë˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    workflow = StateGraph(TutorState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("explain", explain_topic)
    workflow.add_node("quiz", generate_quiz)
    workflow.add_node("review", review_answer)
    workflow.add_node("finish", finish_learning)
    
    # ì—£ì§€ ì—°ê²°
    workflow.add_edge(START, "explain")
    workflow.add_edge("explain", "quiz")
    workflow.add_edge("quiz", "review")
    
    # ì¡°ê±´ë¶€ ì—£ì§€ - ê³„ì†í•˜ê±°ë‚˜ ì¢…ë£Œ
    workflow.add_conditional_edges(
        "review",
        route_learning,
        {
            "continue": "quiz",  # ë‹¤ì‹œ í€´ì¦ˆë¡œ (ë£¨í”„!)
            "finish": "finish"
        }
    )
    
    workflow.add_edge("finish", END)
    
    return workflow.compile()


def main():
    print("=== AI í•™ìŠµ íŠœí„° (LangGraph + LLM) ===")
    print("AI ì„ ìƒë‹˜ê³¼ í•¨ê»˜ í•™ìŠµí•´ë´…ì‹œë‹¤!\n")
    
    # ì£¼ì œ ì…ë ¥
    topic = input("í•™ìŠµí•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜): ")
    
    if not topic:
        topic = "íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜"
        print(f"ê¸°ë³¸ ì£¼ì œ ì„ íƒ: {topic}")
    
    app = create_tutor_graph()
    
    # í•™ìŠµ ì‹œì‘
    initial_state = TutorState(topic=topic, max_quizzes=3)
    result = app.invoke(initial_state)
    
    # ê·¸ë˜í”„ ì‹œê°í™”
    try:
        mermaid_png = app.get_graph().draw_mermaid_png()
        with open("./04_ai_learning_tutor.png", "wb") as f:
            f.write(mermaid_png)
        print("ê·¸ë˜í”„ê°€ 04_ai_learning_tutor.pngë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ê·¸ë˜í”„ ì¶œë ¥ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()

