import os
import json
import feedparser
import schedule
import time
import smtplib
from datetime import datetime
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import List, TypedDict, Annotated, Sequence, Literal
import operator
import functools
import requests
from bs4 import BeautifulSoup

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import BaseMessage, HumanMessage, ToolMessage
from langchain_core.tools import tool
from pydantic import BaseModel, Field

from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from dotenv import load_dotenv


# Configuration
class Config:
    """ì‹œìŠ¤í…œ ì„¤ì •"""
    # Google News RSS URLs
    RSS_URLS = {
        "general": "https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko",
        "technology": "https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGRqTVhZU0FtdHZHZ0pMVWlnQVAB?hl=ko&gl=KR&ceid=KR:ko",
        "business": "https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx6TVdZU0FtdHZHZ0pMVWlnQVAB?hl=ko&gl=KR&ceid=KR:ko",
        "entertainment": "https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNREpxYW5RU0FtdHZHZ0pMVWlnQVAB?hl=ko&gl=KR&ceid=KR:ko",
        "sports": "https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRFp1ZEdvU0FtdHZHZ0pMVWlnQVAB?hl=ko&gl=KR&ceid=KR:ko",
        "health": "https://news.google.com/rss/topics/CAAqIQgKIhtDQkFTRGdvSUwyMHZNR3QwTlRFU0FtdHZLQUFQAQ?hl=ko&gl=KR&ceid=KR:ko"
    }
    
    # Email settings
    SMTP_SERVER = "smtp.gmail.com"
    SMTP_PORT = 587
    EMAIL_ADDRESS = os.getenv("EMAIL_ADDRESS")
    EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
    RECIPIENT_EMAIL = os.getenv("RECIPIENT_EMAIL")
    
    # File settings
    OUTPUT_DIR = "news_reports"
    SCHEDULE_TIME = "09:00"  # ë§¤ì¼ ì˜¤ì „ 9ì‹œ ì‹¤í–‰
    
    # OpenAI settings
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    MODEL_NAME = "gpt-4o-mini"

    @classmethod
    def load_config(cls):
        cls.EMAIL_ADDRESS = os.getenv("EMAIL_ADDRESS")
        cls.EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
        cls.RECIPIENT_EMAIL = os.getenv("RECIPIENT_EMAIL")
        cls.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


# Shared news data storage
news_data_store = {
    "collected_news": [],
    "classified_news": [],
    "summarized_news": [],
    "report_files": {}
}


# State definition for LangGraph
class AgentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    next: str
    
    
class RouteResponse(BaseModel):
    next: Literal["news_collector", "news_classifier", "news_summarizer", "report_generator", "email_sender", "FINISH"]
    
    
# Tools for agents
@tool
def collect_news_from_rss(category: str = "all") -> str:
    """RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    all_news = []
    category_count = {}
    
    if category == "all":
        categories_to_collect = Config.RSS_URLS.keys()
    elif category in Config.RSS_URLS:
        categories_to_collect = [category]
    else:
        return f"Invalid category: {category}. Available categories: {', '.join(Config.RSS_URLS.keys())}"
    
    print(f"\nìˆ˜ì§‘í•  ì¹´í…Œê³ ë¦¬: {list(categories_to_collect)}")
    
    for cat in categories_to_collect:
        try:
            print(f"  - {cat} ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ ì¤‘...")
            feed = feedparser.parse(Config.RSS_URLS[cat])
            count = 0
            for entry in feed.entries[:5]:  # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ 5ê°œì”©ë§Œ ìˆ˜ì§‘ (API í˜¸ì¶œ ìµœì í™”)
                # Google News ë¦¬ë‹¤ì´ë ‰íŠ¸ URL ì²˜ë¦¬
                original_link = entry.get('link', '')
                final_link = original_link
                
                # ìµœì¢… URLì„ ë¯¸ë¦¬ ì–»ì–´ë‘ë©´ ë‚˜ì¤‘ì— ì¤‘ë³µ ìš”ì²­ì„ í”¼í•  ìˆ˜ ìˆìŒ
                if 'news.google.com/rss/articles/' in original_link:
                    try:
                        final_link = get_final_url(original_link, timeout=5)
                    except:
                        final_link = original_link  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                
                news_item = {
                    "title": entry.get('title', ''),
                    "link": final_link,  # ìµœì¢… URL ì €ì¥
                    "original_link": original_link,  # ì›ë³¸ ë§í¬ë„ ë³´ê´€
                    "description": entry.get('description', ''),
                    "pub_date": entry.get('published', ''),
                    "source": entry.get('source', {}).get('title', 'Google News'),
                    "category": cat,
                    "summary": "",
                    "importance_score": 5
                }
                all_news.append(news_item)
                count += 1
            category_count[cat] = count
            print(f"    âœ“ {count}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
        except Exception as e:
            print(f"    âœ— ì—ëŸ¬ ë°œìƒ: {e}")
            category_count[cat] = 0
    
    # Store in shared data
    news_data_store["collected_news"] = all_news
    
    # ìƒì„¸í•œ ê²°ê³¼ ë©”ì‹œì§€
    result_msg = f"ì´ {len(all_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ:\n"
    for cat, count in category_count.items():
        result_msg += f"  - {cat}: {count}ê°œ\n"
    
    return result_msg


# Pydantic models for LLM outputs
class NewsClassification(BaseModel):
    """ë‰´ìŠ¤ ë¶„ë¥˜ ê²°ê³¼"""
    category: str = Field(description="ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ (politics, economy, society, technology, international, culture, sports, entertainment, health, other)")
    importance_score: int = Field(description="ì¤‘ìš”ë„ ì ìˆ˜ (1-10)", ge=1, le=10)
    key_topics: List[str] = Field(description="ì£¼ìš” í† í”½ í‚¤ì›Œë“œ (ìµœëŒ€ 3ê°œ)")
    reasoning: str = Field(description="ë¶„ë¥˜ ì´ìœ ")


class NewsSummary(BaseModel):
    """ë‰´ìŠ¤ ìš”ì•½ ê²°ê³¼"""
    title: str = Field(description="ê°œì„ ëœ ì œëª© (ë” ëª…í™•í•˜ê³  ì •ë³´ê°€ í’ë¶€í•˜ê²Œ)")
    summary: str = Field(description="3-4ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ë‚´ìš© ìš”ì•½")
    key_points: List[str] = Field(description="ì£¼ìš” í¬ì¸íŠ¸ 3-5ê°œ")
    impact: str = Field(description="ì´ ë‰´ìŠ¤ì˜ ì˜í–¥ì´ë‚˜ ì¤‘ìš”ì„±")


# Helper function to fetch article content
def get_final_url(url: str, timeout: int = 10) -> str:
    """Google News ë¦¬ë‹¤ì´ë ‰íŠ¸ URLì—ì„œ ìµœì¢… URL ì–»ê¸°"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # Google News URLì¸ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
        if 'news.google.com/rss/articles/' in url:
            # HEAD ìš”ì²­ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ ì¶”ì 
            response = requests.head(url, headers=headers, allow_redirects=True, timeout=timeout)
            final_url = response.url
            
            # ë•Œë¡œëŠ” GET ìš”ì²­ì´ í•„ìš”í•œ ê²½ìš°ê°€ ìˆìŒ
            if final_url == url or 'google.com' in final_url:
                response = requests.get(url, headers=headers, allow_redirects=True, timeout=timeout)
                final_url = response.url
            
            print(f"    ë¦¬ë‹¤ì´ë ‰íŠ¸: {url[:50]}... â†’ {final_url[:50]}...")
            return final_url
        
        return url
        
    except Exception as e:
        print(f"    ë¦¬ë‹¤ì´ë ‰íŠ¸ í•´ê²° ì‹¤íŒ¨: {e}")
        return url


def fetch_article_content(url: str, timeout: int = 10) -> str:
    """ê¸°ì‚¬ URLì—ì„œ ë³¸ë¬¸ ë‚´ìš© ì¶”ì¶œ"""
    try:
        # ì´ë¯¸ ìµœì¢… URLì¸ ê²½ìš° ë‹¤ì‹œ ë¦¬ë‹¤ì´ë ‰íŠ¸ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
        if 'news.google.com/rss/articles/' in url:
            final_url = get_final_url(url, timeout)
        else:
            final_url = url
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        response = requests.get(final_url, headers=headers, timeout=timeout)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style", "noscript", "iframe"]):
            script.decompose()
        
        # í•œêµ­ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ë³„ ì…€ë ‰í„° ì¶”ê°€
        article_selectors = [
            # ì¼ë°˜ì ì¸ ì…€ë ‰í„°
            'article', 
            '[role="main"]',
            '.article-body',
            '.content',
            '.story-body',
            '.entry-content',
            '#article-body',
            '.post-content',
            # í•œêµ­ ë‰´ìŠ¤ ì‚¬ì´íŠ¸
            '.article_body',  # ë„¤ì´ë²„ ë‰´ìŠ¤
            '#articeBody',    # ë‹¤ìŒ ë‰´ìŠ¤
            '#newsEndContents',  # ë„¤ì´ë²„ ë‰´ìŠ¤ ìŠ¤íƒ ë“œ
            '.news_end',      # ë„¤ì´ë²„
            '.article_view',  # ê°ì¢… ì–¸ë¡ ì‚¬
            '.view_content',  
            '#content',
            '.news_view',
            'div[itemprop="articleBody"]',
            '.article-content'
        ]
        
        article_text = ""
        for selector in article_selectors:
            article = soup.select_one(selector)
            if article:
                # ê´‘ê³ ë‚˜ ê´€ë ¨ ê¸°ì‚¬ ì œê±°
                for ad in article.select('.ad, .advertisement, .related-articles, .photo_table'):
                    ad.decompose()
                
                article_text = article.get_text(separator='\n', strip=True)
                if len(article_text) > 100:  # ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
                    break
        
        # If no article container found, try to get all paragraphs
        if not article_text or len(article_text) < 100:
            paragraphs = soup.find_all('p')
            article_text = '\n'.join([
                p.get_text(strip=True) 
                for p in paragraphs 
                if len(p.get_text(strip=True)) > 30 and 
                not any(skip in p.get_text() for skip in ['ê´‘ê³ ', 'Â©', 'Copyright', 'ë¬´ë‹¨ì „ì¬'])
            ])
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬
        if article_text:
            # ì—°ì†ëœ ê³µë°±ê³¼ ì¤„ë°”ê¿ˆ ì •ë¦¬
            article_text = '\n'.join(line.strip() for line in article_text.split('\n') if line.strip())
            
            # ê¸¸ì´ ì œí•œ
            if len(article_text) > 3000:
                article_text = article_text[:3000] + "..."
        
        if not article_text or len(article_text) < 50:
            return f"ê¸°ì‚¬ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (URL: {final_url[:50]}...)"
            
        return article_text
        
    except requests.exceptions.Timeout:
        return "ê¸°ì‚¬ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹œê°„ ì´ˆê³¼"
    except requests.exceptions.RequestException as e:
        print(f"    ìš”ì²­ ì—ëŸ¬: {e}")
        return "ê¸°ì‚¬ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜)"
    except Exception as e:
        print(f"    ì—ëŸ¬: {e}")
        return "ê¸°ì‚¬ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


@tool
def classify_news_items() -> str:
    """ë‰´ìŠ¤ ì•„ì´í…œ ë¶„ë¥˜ ë° ì¤‘ìš”ë„ ì ìˆ˜ ë¶€ì—¬ (LLM ì‚¬ìš©)"""
    try:
        news_items = news_data_store["collected_news"]
        
        if not news_items:
            return "No news items to classify. Please collect news first."
        
        # LLM ì´ˆê¸°í™”
        llm = ChatOpenAI(model=Config.MODEL_NAME, temperature=0.3)
        
        # ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸
        classification_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë‰´ìŠ¤ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.

ë‰´ìŠ¤ ì •ë³´:
ì œëª©: {title}
ì„¤ëª…: {description}
ì¹´í…Œê³ ë¦¬ íŒíŠ¸: {category_hint}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
1. ì¹´í…Œê³ ë¦¬: politics(ì •ì¹˜), economy(ê²½ì œ), society(ì‚¬íšŒ), technology(ê¸°ìˆ ), international(êµ­ì œ), 
   culture(ë¬¸í™”), sports(ìŠ¤í¬ì¸ ), entertainment(ì—”í„°í…Œì¸ë¨¼íŠ¸), health(ê±´ê°•), other(ê¸°íƒ€) ì¤‘ ì„ íƒ
2. ì¤‘ìš”ë„ ì ìˆ˜ (1-10):
   - 9-10: ì†ë³´, êµ­ê°€ì  ì¤‘ëŒ€ì‚¬, ëŒ€ê·œëª¨ ì˜í–¥
   - 7-8: ì¤‘ìš”í•œ ì •ì±… ë³€ê²½, ì£¼ìš” ê¸°ì—… ë‰´ìŠ¤, ì‚¬íšŒì  ì´ìŠˆ
   - 5-6: ì¼ë°˜ì ì¸ ë‰´ìŠ¤, ì—…ë°ì´íŠ¸, ë°œí‘œ
   - 3-4: ì¼ìƒì ì¸ ë‰´ìŠ¤, ì§€ì—­ ì†Œì‹
   - 1-2: ê°€ì‹­, ë‹¨ìˆœ ì •ë³´

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
""")
        
        classified = []
        batch_size = 5  # ë°°ì¹˜ ì²˜ë¦¬ë¡œ API í˜¸ì¶œ ìµœì í™”
        
        print(f"\nLLMì„ ì‚¬ìš©í•˜ì—¬ {len(news_items)}ê°œ ë‰´ìŠ¤ ë¶„ë¥˜ ì¤‘...")
        
        for i in range(0, len(news_items), batch_size):
            batch = news_items[i:i+batch_size]
            
            for item in batch:
                try:
                    # LLMìœ¼ë¡œ ë¶„ë¥˜
                    chain = classification_prompt | llm.with_structured_output(NewsClassification)
                    result = chain.invoke({
                        "title": item['title'],
                        "description": item.get('description', ''),
                        "category_hint": item.get('category', 'general')
                    })
                    
                    # ê²°ê³¼ ì ìš©
                    item['ai_category'] = result.category
                    item['importance_score'] = result.importance_score
                    item['key_topics'] = result.key_topics
                    item['classification_reasoning'] = result.reasoning
                    
                    classified.append(item)
                    
                except Exception as e:
                    print(f"  ë¶„ë¥˜ ì‹¤íŒ¨ (ê¸°ë³¸ê°’ ì‚¬ìš©): {item['title'][:50]}... - {e}")
                    # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                    item['importance_score'] = 5
                    classified.append(item)
            
            print(f"  ì§„í–‰ë¥ : {min(i+batch_size, len(news_items))}/{len(news_items)}")
        
        # Store in shared data
        news_data_store["classified_news"] = classified
        
        high_importance_count = len([item for item in classified if item['importance_score'] >= 7])
        return f"LLMìœ¼ë¡œ {len(classified)}ê°œ ë‰´ìŠ¤ ë¶„ë¥˜ ì™„ë£Œ. {high_importance_count}ê°œ ê³ ì¤‘ìš”ë„ ë‰´ìŠ¤ ë°œê²¬ (7ì  ì´ìƒ)."
        
    except Exception as e:
        return f"Error classifying news: {e}"


@tool  
def summarize_important_news() -> str:
    """ì¤‘ìš”í•œ ë‰´ìŠ¤ ìš”ì•½ (LLM ì‚¬ìš© ë° ê¸°ì‚¬ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸°)"""
    try:
        classified_news = news_data_store["classified_news"]
        
        if not classified_news:
            return "No classified news to summarize. Please classify news first."
        
        # Filter important news (score >= 7)
        important_news = [item for item in classified_news if item.get('importance_score', 0) >= 7]
        
        if not important_news:
            # ì¤‘ìš” ë‰´ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒìœ„ 5ê°œë¼ë„ ìš”ì•½
            important_news = sorted(classified_news, key=lambda x: x.get('importance_score', 0), reverse=True)[:5]
            print(f"\nì¤‘ìš”ë„ 7 ì´ìƒ ë‰´ìŠ¤ê°€ ì—†ì–´ ìƒìœ„ {len(important_news)}ê°œ ë‰´ìŠ¤ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.")
        
        # LLM ì´ˆê¸°í™”
        llm = ChatOpenAI(model=Config.MODEL_NAME, temperature=0.3)
        
        # ìš”ì•½ í”„ë¡¬í”„íŠ¸
        summary_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë‰´ìŠ¤ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.

ë‰´ìŠ¤ ì •ë³´:
ì œëª©: {title}
ì„¤ëª…: {description}
ë³¸ë¬¸ ë‚´ìš©: {article_content}
ì¤‘ìš”ë„: {importance_score}/10
ë¶„ë¥˜ ì´ìœ : {classification_reasoning}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
1. ê°œì„ ëœ ì œëª©: ë” ëª…í™•í•˜ê³  ì •ë³´ê°€ í’ë¶€í•œ ì œëª©
2. ìš”ì•½: 3-4ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ë‚´ìš© ìš”ì•½
3. ì£¼ìš” í¬ì¸íŠ¸: 3-5ê°œì˜ í•µì‹¬ ì‚¬í•­
4. ì˜í–¥/ì¤‘ìš”ì„±: ì´ ë‰´ìŠ¤ê°€ ì™œ ì¤‘ìš”í•œì§€

ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
""")
        
        summarized = []
        fetch_content = True  # ê¸°ì‚¬ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸° ì—¬ë¶€
        
        print(f"\nLLMì„ ì‚¬ìš©í•˜ì—¬ {len(important_news)}ê°œ ì¤‘ìš” ë‰´ìŠ¤ ìš”ì•½ ì¤‘...")
        
        for idx, item in enumerate(important_news):
            try:
                article_content = "ë³¸ë¬¸ ì—†ìŒ"
                
                # ê¸°ì‚¬ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸° (ì„ íƒì )
                if fetch_content and item.get('link'):
                    print(f"  [{idx+1}/{len(important_news)}] ê¸°ì‚¬ ë³¸ë¬¸ ê°€ì ¸ì˜¤ëŠ” ì¤‘: {item['title'][:50]}...")
                    # ì´ë¯¸ ìµœì¢… URLì´ ìˆê±°ë‚˜ original_linkê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©
                    article_url = item.get('link', item.get('original_link', ''))
                    article_content = fetch_article_content(article_url)
                    if len(article_content) > 50:  # ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì˜¨ ê²½ìš°
                        print(f"    âœ“ ë³¸ë¬¸ {len(article_content)}ì ê°€ì ¸ì˜´")
                    else:
                        print(f"    âœ— ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨")
                
                # LLMìœ¼ë¡œ ìš”ì•½
                chain = summary_prompt | llm.with_structured_output(NewsSummary)
                result = chain.invoke({
                    "title": item['title'],
                    "description": item.get('description', ''),
                    "article_content": article_content[:2000],  # í† í° ì œí•œì„ ìœ„í•´ 2000ìë¡œ ì œí•œ
                    "importance_score": item.get('importance_score', 5),
                    "classification_reasoning": item.get('classification_reasoning', '')
                })
                
                # ê²°ê³¼ ì ìš©
                item['improved_title'] = result.title
                item['summary'] = result.summary
                item['key_points'] = result.key_points
                item['impact'] = result.impact
                item['has_full_content'] = len(article_content) > 100
                
                summarized.append(item)
                print(f"    âœ“ ìš”ì•½ ì™„ë£Œ")
                
            except Exception as e:
                print(f"  ìš”ì•½ ì‹¤íŒ¨ (ê¸°ë³¸ ìš”ì•½ ì‚¬ìš©): {item['title'][:50]}... - {e}")
                # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìš”ì•½
                item['summary'] = f"[ì¤‘ìš”ë„ {item.get('importance_score', 5)}] {item['title']}"
                item['key_points'] = ["ìš”ì•½ ìƒì„± ì‹¤íŒ¨"]
                summarized.append(item)
        
        # Store in shared data
        news_data_store["summarized_news"] = summarized
        
        # ì „ì²´ ë‰´ìŠ¤ì—ë„ ìš”ì•½ ì •ë³´ ì—…ë°ì´íŠ¸
        for item in news_data_store["classified_news"]:
            for summ_item in summarized:
                if item['link'] == summ_item['link']:
                    item.update(summ_item)
                    break
        
        return f"LLMìœ¼ë¡œ {len(summarized)}ê°œ ë‰´ìŠ¤ ìš”ì•½ ì™„ë£Œ. ê¸°ì‚¬ ë³¸ë¬¸ ìˆ˜ì§‘: {len([x for x in summarized if x.get('has_full_content')])}ê°œ"
        
    except Exception as e:
        return f"Error summarizing news: {e}"


@tool
def generate_news_report() -> str:
    """ë‰´ìŠ¤ ë¦¬í¬íŠ¸ ìƒì„±"""
    try:
        all_news = news_data_store["classified_news"]
        summarized_news = news_data_store["summarized_news"]
        
        if not all_news:
            return "No news data available for report generation."
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Create output directory
        if not os.path.exists(Config.OUTPUT_DIR):
            os.makedirs(Config.OUTPUT_DIR)
        
        # Organize news by category
        news_by_category = {}
        for item in all_news:
            cat = item.get('category', 'other')
            if cat not in news_by_category:
                news_by_category[cat] = []
            news_by_category[cat].append(item)
        
        # Create report structure
        report = {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "time": datetime.now().strftime("%H:%M:%S"),
            "total_news": len(all_news),
            "important_news_count": len(summarized_news),
            "news_by_category": {cat: len(items) for cat, items in news_by_category.items()},
            "all_news": all_news,
            "top_news": summarized_news
        }
        
        # Save JSON report
        json_filename = f"{Config.OUTPUT_DIR}/news_report_{timestamp}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # Generate HTML report
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>ë‰´ìŠ¤ ë¦¬í¬íŠ¸ - {report['date']}</title>
            <style>
                body {{ 
                    font-family: 'Malgun Gothic', sans-serif; 
                    margin: 20px;
                    background-color: #f5f5f5;
                }}
                .container {{
                    max-width: 1200px;
                    margin: 0 auto;
                    background-color: white;
                    padding: 20px;
                    border-radius: 10px;
                    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                }}
                h1 {{ 
                    color: #333;
                    border-bottom: 3px solid #0066cc;
                    padding-bottom: 10px;
                }}
                h2 {{
                    color: #0066cc;
                    margin-top: 30px;
                    border-bottom: 2px solid #e9ecef;
                    padding-bottom: 10px;
                }}
                h3 {{
                    color: #333;
                    margin-top: 20px;
                }}
                .stats {{
                    display: flex;
                    gap: 20px;
                    margin: 20px 0;
                }}
                .stat-box {{
                    background: #f8f9fa;
                    padding: 15px;
                    border-radius: 5px;
                    flex: 1;
                    text-align: center;
                }}
                .news-item {{
                    margin: 15px 0;
                    padding: 15px;
                    border-left: 3px solid #0066cc;
                    background: #f8f9fa;
                }}
                .important-news {{
                    border-left-color: #ff6b6b;
                    background: #fff5f5;
                }}
                .category-stats {{
                    margin: 20px 0;
                }}
                .category-stat {{
                    display: inline-block;
                    margin: 5px;
                    padding: 5px 10px;
                    background: #e9ecef;
                    border-radius: 3px;
                }}
                .importance-badge {{
                    display: inline-block;
                    padding: 2px 8px;
                    border-radius: 3px;
                    font-size: 0.85em;
                    font-weight: bold;
                }}
                .importance-high {{ background: #ffebee; color: #c62828; }}
                .importance-medium {{ background: #fff3e0; color: #ef6c00; }}
                .importance-low {{ background: #e8f5e9; color: #2e7d32; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>ğŸ“° ì¼ì¼ ë‰´ìŠ¤ ë¦¬í¬íŠ¸</h1>
                <p><strong>ë‚ ì§œ:</strong> {report['date']} {report['time']}</p>
                
                <div class="stats">
                    <div class="stat-box">
                        <h3>ì „ì²´ ë‰´ìŠ¤</h3>
                        <p style="font-size: 2em; color: #0066cc;">{report['total_news']}ê±´</p>
                    </div>
                    <div class="stat-box">
                        <h3>ì¤‘ìš” ë‰´ìŠ¤</h3>
                        <p style="font-size: 2em; color: #ff6b6b;">{report['important_news_count']}ê±´</p>
                    </div>
                </div>
                
                <div class="category-stats">
                    <h2>ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ í†µê³„</h2>
                    {''.join([f'<span class="category-stat">{cat}: {count}ê±´</span>' for cat, count in report['news_by_category'].items()])}
                </div>
        """
        
        # ì¤‘ìš” ë‰´ìŠ¤ ì„¹ì…˜
        if summarized_news:
            html_content += """
                <h2>ğŸ”¥ ì¤‘ìš” ë‰´ìŠ¤ (ì¤‘ìš”ë„ 7 ì´ìƒ)</h2>
            """
            for item in summarized_news:
                importance_class = "importance-high" if item['importance_score'] >= 8 else "importance-medium"
                improved_title = item.get('improved_title', item['title'])
                
                html_content += f'''
                    <div class="news-item important-news">
                        <h4>{improved_title}</h4>
                        <p>
                            <strong>ì¹´í…Œê³ ë¦¬:</strong> {item.get("ai_category", item.get("category", "ê¸°íƒ€"))} | 
                            <span class="importance-badge {importance_class}">ì¤‘ìš”ë„: {item.get("importance_score", "N/A")}/10</span>
                            {' | <span style="color: green;">âœ“ ë³¸ë¬¸ ë¶„ì„ ì™„ë£Œ</span>' if item.get('has_full_content') else ''}
                        </p>
                        <p><strong>ìš”ì•½:</strong> {item.get("summary", item.get("description", ""))}</p>
                        
                        {f'<p><strong>ì£¼ìš” í¬ì¸íŠ¸:</strong><ul>{"".join([f"<li>{point}</li>" for point in item.get("key_points", [])])}</ul></p>' if item.get('key_points') else ''}
                        
                        {f'<p><strong>ì˜í–¥/ì¤‘ìš”ì„±:</strong> {item.get("impact", "")}</p>' if item.get('impact') else ''}
                        
                        <p><strong>ì›ë³¸ ì œëª©:</strong> {item["title"]}</p>
                        <p><a href="{item.get("link", "#")}" target="_blank">ìì„¸íˆ ë³´ê¸° â†’</a></p>
                    </div>
                '''
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì „ì²´ ë‰´ìŠ¤
        html_content += """
            <h2>ğŸ“‹ ì¹´í…Œê³ ë¦¬ë³„ ì „ì²´ ë‰´ìŠ¤</h2>
        """
        
        for category, items in sorted(news_by_category.items()):
            html_content += f"""
                <h3>{category.upper()} ({len(items)}ê±´)</h3>
            """
            for item in sorted(items, key=lambda x: x.get('importance_score', 0), reverse=True):
                importance = item.get('importance_score', 0)
                if importance >= 8:
                    importance_class = "importance-high"
                elif importance >= 6:
                    importance_class = "importance-medium"
                else:
                    importance_class = "importance-low"
                    
                html_content += f'''
                    <div class="news-item">
                        <h4>{item.get('improved_title', item['title'])}</h4>
                        <p>
                            <span class="importance-badge {importance_class}">ì¤‘ìš”ë„: {importance}/10</span> | 
                            <strong>AI ì¹´í…Œê³ ë¦¬:</strong> {item.get('ai_category', item.get('category', 'ê¸°íƒ€'))} |
                            <strong>ë°œí–‰ì¼:</strong> {item.get("pub_date", "N/A")}
                        </p>
                        <p>{item.get('summary', item.get('description', ''))[:200]}...</p>
                        {f'<p><strong>ì£¼ìš” í† í”½:</strong> {", ".join(item.get("key_topics", []))}</p>' if item.get('key_topics') else ''}
                        <p><a href="{item.get("link", "#")}" target="_blank">ìì„¸íˆ ë³´ê¸° â†’</a></p>
                    </div>
                '''
        
        html_content += """
            </div>
        </body>
        </html>
        """
        
        html_filename = f"{Config.OUTPUT_DIR}/news_report_{timestamp}.html"
        with open(html_filename, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        # Store file paths and HTML content
        news_data_store["report_files"] = {
            "json": json_filename,
            "html": html_filename
        }
        news_data_store["html_content"] = html_content
        
        return f"Report generated successfully! JSON: {json_filename}, HTML: {html_filename}"
        
    except Exception as e:
        return f"Error generating report: {e}"


@tool
def send_email_report() -> str:
    """ì´ë©”ì¼ë¡œ ë¦¬í¬íŠ¸ ë°œì†¡"""
    print("\nì´ë©”ì¼ ë°œì†¡ ì‹œì‘...")
    
    # ì´ë©”ì¼ ì„¤ì • í™•ì¸
    if not Config.EMAIL_ADDRESS:
        return "ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: EMAIL_ADDRESSê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    if not Config.EMAIL_PASSWORD:
        return "ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: EMAIL_PASSWORDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    if not Config.RECIPIENT_EMAIL:
        return "ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: RECIPIENT_EMAILì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    print(f"ë°œì‹ ì: {Config.EMAIL_ADDRESS}")
    print(f"ìˆ˜ì‹ ì: {Config.RECIPIENT_EMAIL}")

    try:
        # HTML ì»¨í…ì¸  ê°€ì ¸ì˜¤ê¸°
        html_content = news_data_store.get("html_content", "")
        if not html_content:
            return "ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: ë°œì†¡í•  ë¦¬í¬íŠ¸ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # í†µê³„ ì •ë³´
        total_news = len(news_data_store.get('classified_news', []))
        important_news = len(news_data_store.get('summarized_news', []))
        
        # ì´ë©”ì¼ ìƒì„±
        msg = MIMEMultipart('alternative')
        msg['From'] = Config.EMAIL_ADDRESS
        msg['To'] = Config.RECIPIENT_EMAIL
        msg['Subject'] = f"ğŸ“° ì¼ì¼ ë‰´ìŠ¤ ë¦¬í¬íŠ¸ - {datetime.now().strftime('%Y-%m-%d')} (ì´ {total_news}ê±´)"
        
        # í…ìŠ¤íŠ¸ ë²„ì „ (HTMLì„ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë©”ì¼ í´ë¼ì´ì–¸íŠ¸ìš©)
        text_body = f"""
ì¼ì¼ ë‰´ìŠ¤ ë¦¬í¬íŠ¸ - {datetime.now().strftime('%Yë…„ %mì›” %dì¼')}

â–  ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ ìš”ì•½
- ì´ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {total_news}ê±´
- ì¤‘ìš” ë‰´ìŠ¤: {important_news}ê±´

â–  ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤
"""
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ì¶”ê°€
        category_stats = {}
        for item in news_data_store.get('classified_news', []):
            cat = item.get('category', 'other')
            category_stats[cat] = category_stats.get(cat, 0) + 1
        
        for cat, count in category_stats.items():
            text_body += f"  - {cat}: {count}ê±´\n"
        
        # ì¤‘ìš” ë‰´ìŠ¤ ëª©ë¡ ì¶”ê°€
        if news_data_store.get('summarized_news'):
            text_body += "\nâ–  ì£¼ìš” ë‰´ìŠ¤\n"
            for idx, item in enumerate(news_data_store['summarized_news'][:10], 1):
                improved_title = item.get('improved_title', item['title'])
                text_body += f"\n{idx}. {improved_title}\n"
                text_body += f"   ì¤‘ìš”ë„: {item.get('importance_score', 'N/A')}/10 | ì¹´í…Œê³ ë¦¬: {item.get('ai_category', item.get('category', 'ê¸°íƒ€'))}\n"
                text_body += f"   {item.get('summary', '')}\n"
                if item.get('impact'):
                    text_body += f"   â–¶ {item.get('impact')}\n"
        
        text_body += """
        
ìì„¸í•œ ë‚´ìš©ì€ HTML ë²„ì „ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‰´ìŠ¤ ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
        """
        
        # ì´ë©”ì¼ìš© HTML ìŠ¤íƒ€ì¼ ì¡°ì • (ì¸ë¼ì¸ ìŠ¤íƒ€ì¼ë¡œ ë³€ê²½)
        email_html_content = html_content
        # ì¼ë¶€ ì´ë©”ì¼ í´ë¼ì´ì–¸íŠ¸ëŠ” <style> íƒœê·¸ë¥¼ ë¬´ì‹œí•˜ë¯€ë¡œ ì¤‘ìš”í•œ ìŠ¤íƒ€ì¼ì„ ì¸ë¼ì¸ìœ¼ë¡œ ì¶”ê°€
        email_html_content = email_html_content.replace(
            '<div class="container">',
            '<div class="container" style="max-width: 1200px; margin: 0 auto; background-color: white; padding: 20px;">'
        )
        email_html_content = email_html_content.replace(
            '<div class="news-item">',
            '<div class="news-item" style="margin: 15px 0; padding: 15px; border-left: 3px solid #0066cc; background: #f8f9fa;">'
        )
        email_html_content = email_html_content.replace(
            '<div class="news-item important-news">',
            '<div class="news-item important-news" style="margin: 15px 0; padding: 15px; border-left: 3px solid #ff6b6b; background: #fff5f5;">'
        )
        
        # MIMEText ê°ì²´ ìƒì„±
        text_part = MIMEText(text_body, 'plain', 'utf-8')
        html_part = MIMEText(email_html_content, 'html', 'utf-8')
        
        # ë©”ì‹œì§€ì— ì¶”ê°€
        msg.attach(text_part)
        msg.attach(html_part)
        
        # ì´ë©”ì¼ ë°œì†¡
        print("SMTP ì„œë²„ ì—°ê²° ì¤‘...")
        with smtplib.SMTP(Config.SMTP_SERVER, Config.SMTP_PORT) as server:
            server.set_debuglevel(0)  # ë””ë²„ê·¸ ë ˆë²¨ ë‚®ì¶¤
            print("TLS ì‹œì‘...")
            server.starttls()
            print("ë¡œê·¸ì¸ ì¤‘...")
            server.login(Config.EMAIL_ADDRESS, Config.EMAIL_PASSWORD)
            print("ì´ë©”ì¼ ë°œì†¡ ì¤‘...")
            server.send_message(msg)
        
        success_msg = f"ì´ë©”ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤! (ìˆ˜ì‹ ì: {Config.RECIPIENT_EMAIL})"
        print(f"âœ“ {success_msg}")
        return success_msg
        
    except smtplib.SMTPAuthenticationError as e:
        error_msg = f"ì´ë©”ì¼ ì¸ì¦ ì‹¤íŒ¨: Gmailì˜ ê²½ìš° ì•± ë¹„ë°€ë²ˆí˜¸ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ì—ëŸ¬: {e}"
        print(f"âœ— {error_msg}")
        print("\nì•± ë¹„ë°€ë²ˆí˜¸ ì„¤ì • ë°©ë²•:")
        print("1. Google ê³„ì • ì„¤ì • > ë³´ì•ˆìœ¼ë¡œ ì´ë™")
        print("2. 2ë‹¨ê³„ ì¸ì¦ í™œì„±í™”")
        print("3. ì•± ë¹„ë°€ë²ˆí˜¸ ìƒì„±")
        print("4. ìƒì„±ëœ 16ìë¦¬ ë¹„ë°€ë²ˆí˜¸ë¥¼ EMAIL_PASSWORDë¡œ ì‚¬ìš©")
        return error_msg
    except smtplib.SMTPException as e:
        error_msg = f"SMTP ì—ëŸ¬: {e}"
        print(f"âœ— {error_msg}")
        return error_msg
    except Exception as e:
        error_msg = f"ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}"
        print(f"âœ— {error_msg}")
        import traceback
        traceback.print_exc()
        return error_msg


# Create agent functions
def create_agent(llm, tools, system_message: str):
    """Helper function to create an agent"""
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        MessagesPlaceholder(variable_name="messages"),
    ])
    prompt = prompt.partial(tools=", ".join([tool.name for tool in tools]))
    return prompt | llm.bind_tools(tools)


def agent_node(state, agent, name):
    """Agent node function"""
    result = agent.invoke(state)
    # Convert result to HumanMessage as supervisor expects
    if hasattr(result, 'tool_calls') and result.tool_calls:
        return {"messages": [result]}
    else:
        # If no tool calls, create a message
        return {"messages": [HumanMessage(content=result.content if hasattr(result, 'content') else str(result), name=name)]}


# Supervisor function
members = ["news_collector", "news_classifier", "news_summarizer", "report_generator", "email_sender"]
options = ["FINISH"] + members

def supervisor_agent(state):
    """Supervisor agent that routes to next agent"""
    supervisor_prompt = ChatPromptTemplate.from_messages([
        ("system", """You are a supervisor tasked with managing a conversation between the following workers: {members}. 
Given the following user request, respond with the worker to act next. Each worker will perform a task and respond with their results and status.

The workers should be called in this order:
1. news_collector - to collect news from RSS feeds
2. news_classifier - to classify and score the collected news
3. news_summarizer - to summarize important news items
4. report_generator - to create news reports
5. email_sender - to send the report via email

When all tasks are complete, respond with FINISH."""),
        MessagesPlaceholder(variable_name="messages"),
    ]).partial(members=", ".join(members))
    
    model = ChatOpenAI(model=Config.MODEL_NAME, temperature=0)
    
    supervisor_chain = supervisor_prompt | model.with_structured_output(RouteResponse)
    
    return {"next": supervisor_chain.invoke(state).next}


class NewsMultiAgentSystem:
    """ë‰´ìŠ¤ ë©€í‹°ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=Config.MODEL_NAME,
            temperature=0,
            openai_api_key=Config.OPENAI_API_KEY
        )
        
        # Build the graph
        workflow = StateGraph(AgentState)
        
        # Create nodes
        collector_agent = create_agent(
            self.llm,
            [collect_news_from_rss],
            "You are a news collection specialist. Use the collect_news_from_rss tool to collect news. Always call the tool with category='all'."
        )
        collector_node = functools.partial(agent_node, agent=collector_agent, name="news_collector")
        
        classifier_agent = create_agent(
            self.llm,
            [classify_news_items],
            "You are a news classification specialist. Use the classify_news_items tool to classify collected news. This tool uses LLM to analyze and categorize news with importance scores."
        )
        classifier_node = functools.partial(agent_node, agent=classifier_agent, name="news_classifier")
        
        summarizer_agent = create_agent(
            self.llm,
            [summarize_important_news],
            "You are a news summarization specialist. Use the summarize_important_news tool to summarize classified news. This tool uses LLM and fetches full article content for better summaries."
        )
        summarizer_node = functools.partial(agent_node, agent=summarizer_agent, name="news_summarizer")
        
        generator_agent = create_agent(
            self.llm,
            [generate_news_report],
            "You are a report generation specialist. Use the generate_news_report tool to create reports."
        )
        generator_node = functools.partial(agent_node, agent=generator_agent, name="report_generator")
        
        sender_agent = create_agent(
            self.llm,
            [send_email_report],
            "You are an email sending specialist. Use the send_email_report tool to send reports."
        )
        sender_node = functools.partial(agent_node, agent=sender_agent, name="email_sender")
        
        # Add nodes
        workflow.add_node("supervisor", supervisor_agent)
        workflow.add_node("news_collector", collector_node)
        workflow.add_node("news_classifier", classifier_node)
        workflow.add_node("news_summarizer", summarizer_node)
        workflow.add_node("report_generator", generator_node)
        workflow.add_node("email_sender", sender_node)
        
        # Tool nodes
        workflow.add_node("collector_tools", ToolNode([collect_news_from_rss]))
        workflow.add_node("classifier_tools", ToolNode([classify_news_items]))
        workflow.add_node("summarizer_tools", ToolNode([summarize_important_news]))
        workflow.add_node("generator_tools", ToolNode([generate_news_report]))
        workflow.add_node("sender_tools", ToolNode([send_email_report]))
        
        # Add conditional edges for each agent
        for member, tool_node in [
            ("news_collector", "collector_tools"),
            ("news_classifier", "classifier_tools"),
            ("news_summarizer", "summarizer_tools"),
            ("report_generator", "generator_tools"),
            ("email_sender", "sender_tools")
        ]:
            workflow.add_conditional_edges(
                member,
                lambda x: "continue" if x["messages"][-1].tool_calls else "end",
                {
                    "continue": tool_node,
                    "end": "supervisor"
                }
            )
        
        # Add edges from tools back to supervisor
        for tool_node in ["collector_tools", "classifier_tools", "summarizer_tools", "generator_tools", "sender_tools"]:
            workflow.add_edge(tool_node, "supervisor")
        
        # Conditional routing from supervisor
        conditional_map = {k: k for k in members}
        conditional_map["FINISH"] = END
        workflow.add_conditional_edges("supervisor", lambda x: x["next"], conditional_map)
        
        # Set entry point
        workflow.add_edge("__start__", "supervisor")
        
        # Compile
        checkpointer = MemorySaver()
        self.app = workflow.compile(checkpointer=checkpointer)
    
    def run_pipeline(self):
        """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print(f"ë‰´ìŠ¤ ì²˜ë¦¬ ì‹œì‘: {datetime.now()}")
        print(f"{'='*60}")
        
        # Clear previous data
        news_data_store.clear()
        news_data_store.update({
            "collected_news": [],
            "classified_news": [],
            "summarized_news": [],
            "report_files": {}
        })
        
        # Configuration
        config = {
            "configurable": {"thread_id": f"news_{datetime.now().strftime('%Y%m%d_%H%M%S')}"},
            "recursion_limit": 100  # Increase recursion limit further
        }
        
        # Initial message
        initial_message = HumanMessage(
            content="Please process today's news: collect all news, classify them, summarize important ones, generate a report, and send it via email."
        )
        
        try:
            # Run the workflow with streaming
            for output in self.app.stream(
                {"messages": [initial_message]},
                config=config,
                stream_mode="values"
            ):
                if "messages" in output:
                    last_message = output["messages"][-1]
                    if hasattr(last_message, 'content') and last_message.content:
                        # Tool ë©”ì‹œì§€ì¸ ê²½ìš° ì „ì²´ ë‚´ìš© ì¶œë ¥
                        if isinstance(last_message, ToolMessage):
                            print(f"\n[Tool Result]: {last_message.content}")
                        else:
                            print(f"\n[Agent]: {last_message.content[:200]}...")
            
            # Print summary
            print(f"\n{'='*60}")
            print("ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½")
            print(f"{'='*60}")
            print(f"âœ“ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {len(news_data_store['collected_news'])}ê±´")
            print(f"âœ“ ë¶„ë¥˜ëœ ë‰´ìŠ¤: {len(news_data_store['classified_news'])}ê±´")
            print(f"âœ“ ìš”ì•½ëœ ì¤‘ìš” ë‰´ìŠ¤: {len(news_data_store['summarized_news'])}ê±´")
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            if news_data_store['classified_news']:
                print("\nì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ ìˆ˜:")
                category_stats = {}
                for item in news_data_store['classified_news']:
                    cat = item.get('category', 'other')
                    category_stats[cat] = category_stats.get(cat, 0) + 1
                for cat, count in sorted(category_stats.items()):
                    print(f"  - {cat}: {count}ê±´")
            
            if news_data_store['report_files']:
                print(f"\nìƒì„±ëœ ë¦¬í¬íŠ¸:")
                for file_type, file_path in news_data_store['report_files'].items():
                    print(f"  - {file_type.upper()}: {file_path}")
                    if os.path.exists(file_path):
                        file_size = os.path.getsize(file_path)
                        print(f"    (íŒŒì¼ í¬ê¸°: {file_size:,} bytes)")
            
            print(f"\në‰´ìŠ¤ ì²˜ë¦¬ ì™„ë£Œ: {datetime.now()}")
            print(f"{'='*60}\n")
            
        except Exception as e:
            print(f"\n{'='*60}")
            print(f"Error during pipeline execution: {e}")
            print(f"{'='*60}")
            import traceback
            traceback.print_exc()
    
    def schedule_daily_run(self):
        """ë§¤ì¼ ì •í•´ì§„ ì‹œê°„ì— ì‹¤í–‰"""
        schedule.every().day.at(Config.SCHEDULE_TIME).do(self.run_pipeline)
        
        print(f"ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘: ë§¤ì¼ {Config.SCHEDULE_TIME}ì— ì‹¤í–‰ë©ë‹ˆë‹¤.")
        
        while True:
            schedule.run_pending()
            time.sleep(60)


def main():
    """ë©”ì¸ í•¨ìˆ˜
    
    í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:
    pip install langchain langgraph langchain-openai feedparser schedule python-dotenv requests beautifulsoup4
    """
    
    system = NewsMultiAgentSystem()
    
    # ì˜µì…˜ 1: ì¦‰ì‹œ ì‹¤í–‰
    system.run_pipeline()
    
    # ì˜µì…˜ 2: ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ ë§¤ì¼ ì‹¤í–‰
    # system.schedule_daily_run()


if __name__ == "__main__":
    load_dotenv()
    Config.load_config()
    
    # API í‚¤ í™•ì¸
    if not Config.OPENAI_API_KEY:
        print("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        print("export OPENAI_API_KEY='your-api-key'")
        exit(1)
    
    # ì´ë©”ì¼ ì„¤ì • í™•ì¸
    if not all([Config.EMAIL_ADDRESS, Config.EMAIL_PASSWORD, Config.RECIPIENT_EMAIL]):
        print("\n" + "="*60)
        print("âš ï¸  ì´ë©”ì¼ ì„¤ì • ì•ˆë‚´")
        print("="*60)
        print("ì´ë©”ì¼ ê´€ë ¨ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì´ë©”ì¼ì„ ë°›ìœ¼ë ¤ë©´ ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ë¥¼ .env íŒŒì¼ì— ì¶”ê°€í•˜ì„¸ìš”:")
        print()
        print("EMAIL_ADDRESS=your_email@gmail.com")
        print("EMAIL_PASSWORD=your_app_password  # Gmail ì•± ë¹„ë°€ë²ˆí˜¸")
        print("RECIPIENT_EMAIL=recipient@gmail.com")
        print()
        print("ğŸ“Œ Gmail ì•± ë¹„ë°€ë²ˆí˜¸ ì„¤ì • ë°©ë²•:")
        print("1. Google ê³„ì • ì„¤ì • (https://myaccount.google.com)")
        print("2. ë³´ì•ˆ â†’ 2ë‹¨ê³„ ì¸ì¦ í™œì„±í™”")
        print("3. ë³´ì•ˆ â†’ ì•± ë¹„ë°€ë²ˆí˜¸ ìƒì„±")
        print("4. ì•± ì„ íƒ: ë©”ì¼, ê¸°ê¸° ì„ íƒ: ê¸°íƒ€(ì‚¬ìš©ì ì§€ì •)")
        print("5. ìƒì„±ëœ 16ìë¦¬ ë¹„ë°€ë²ˆí˜¸ë¥¼ EMAIL_PASSWORDë¡œ ì‚¬ìš©")
        print("="*60 + "\n")
    else:
        print("\nâœ“ ì´ë©”ì¼ ì„¤ì • í™•ì¸ë¨")
        print(f"  ë°œì‹ ì: {Config.EMAIL_ADDRESS}")
        print(f"  ìˆ˜ì‹ ì: {Config.RECIPIENT_EMAIL}")

    main()